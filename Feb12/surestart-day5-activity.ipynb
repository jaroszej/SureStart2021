{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-02-15T23:58:11.392408Z",
     "iopub.status.busy": "2021-02-15T23:58:11.391350Z",
     "iopub.status.idle": "2021-02-15T23:58:11.408660Z",
     "shell.execute_reply": "2021-02-15T23:58:11.409274Z"
    },
    "papermill": {
     "duration": 0.029512,
     "end_time": "2021-02-15T23:58:11.409630",
     "exception": false,
     "start_time": "2021-02-15T23:58:11.380118",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/news-headlines-dataset-for-sarcasm-detection/Sarcasm_Headlines_Dataset_v2.json\n",
      "/kaggle/input/news-headlines-dataset-for-sarcasm-detection/Sarcasm_Headlines_Dataset.json\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-15T23:58:11.432105Z",
     "iopub.status.busy": "2021-02-15T23:58:11.431401Z",
     "iopub.status.idle": "2021-02-15T23:58:18.163965Z",
     "shell.execute_reply": "2021-02-15T23:58:18.163242Z"
    },
    "papermill": {
     "duration": 6.746518,
     "end_time": "2021-02-15T23:58:18.164112",
     "exception": false,
     "start_time": "2021-02-15T23:58:11.417594",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Necessary packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.model_selection import cross_val_score as cvs\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from tensorflow.keras.losses import MeanSquaredError as mse\n",
    "import sklearn.metrics\n",
    "from sklearn.metrics import confusion_matrix as cm\n",
    "from sklearn.metrics import precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-15T23:58:18.191403Z",
     "iopub.status.busy": "2021-02-15T23:58:18.190705Z",
     "iopub.status.idle": "2021-02-15T23:58:18.403155Z",
     "shell.execute_reply": "2021-02-15T23:58:18.403650Z"
    },
    "papermill": {
     "duration": 0.232405,
     "end_time": "2021-02-15T23:58:18.403846",
     "exception": false,
     "start_time": "2021-02-15T23:58:18.171441",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/news-headlines-dataset-for-sarcasm-detection/Sarcasm_Headlines_Dataset_v2.json\n",
      "/kaggle/input/news-headlines-dataset-for-sarcasm-detection/Sarcasm_Headlines_Dataset.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'is_sarcastic': 1,\n",
       " 'headline': 'thirtysomething scientists unveil doomsday clock of hair loss',\n",
       " 'article_link': 'https://www.theonion.com/thirtysomething-scientists-unveil-doomsday-clock-of-hai-1819586205'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting pathnames for each file in the input folder\n",
    "for dirname, _, filenames in os.walk('/kaggle/input/news-headlines-dataset-for-sarcasm-detection'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "#Function to parse data\n",
    "def parse_data(file):\n",
    "    for l in open(file,'r'):\n",
    "        yield json.loads(l)\n",
    "\n",
    "#Taking in the data in one of the json files (I'm using the slightly larger one)\n",
    "data = list(parse_data(\"/kaggle/input/news-headlines-dataset-for-sarcasm-detection/Sarcasm_Headlines_Dataset_v2.json\"))\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.007468,
     "end_time": "2021-02-15T23:58:18.419113",
     "exception": false,
     "start_time": "2021-02-15T23:58:18.411645",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "We need to separate the data from this list into X and y\n",
    "Our X is going to be a vectorized list of words from the headline.\n",
    "Our y is going to be \"is_sarcastic\".\n",
    "To do this, we're going to use some NLP packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-15T23:58:18.468943Z",
     "iopub.status.busy": "2021-02-15T23:58:18.463694Z",
     "iopub.status.idle": "2021-02-15T23:58:19.044144Z",
     "shell.execute_reply": "2021-02-15T23:58:19.043592Z"
    },
    "papermill": {
     "duration": 0.617529,
     "end_time": "2021-02-15T23:58:19.044327",
     "exception": false,
     "start_time": "2021-02-15T23:58:18.426798",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Creating our X variable\n",
    "vectorizer = TfidfVectorizer(max_features=50, use_idf=False)\n",
    "headlines = [i['headline'] for i in data]\n",
    "X = vectorizer.fit_transform(headlines).toarray()\n",
    "\n",
    "#Creating our y variable\n",
    "y = np.ravel([i['is_sarcastic'] for i in data])\n",
    "\n",
    "#Creating a train and test split\n",
    "X_train, X_test, y_train, y_test = tts(X, y, test_size = 0.2, random_state = 1693)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-15T23:58:19.066596Z",
     "iopub.status.busy": "2021-02-15T23:58:19.065888Z",
     "iopub.status.idle": "2021-02-15T23:58:19.155919Z",
     "shell.execute_reply": "2021-02-15T23:58:19.155281Z"
    },
    "papermill": {
     "duration": 0.103397,
     "end_time": "2021-02-15T23:58:19.156067",
     "exception": false,
     "start_time": "2021-02-15T23:58:19.052670",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Now we're going to build the model with its layers\n",
    "\n",
    "#Initialize the model\n",
    "model = Sequential([\n",
    "    # first layer\n",
    "    Dense(units=24, input_shape=(50,), activation='softmax'),\n",
    "    # second layer\n",
    "    Dense(12, activation = 'softmax'),\n",
    "    # third layer\n",
    "    Dense(8, activation = 'softmax'),\n",
    "    # output layer\n",
    "    Dense(1, activation = 'sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-15T23:58:19.187090Z",
     "iopub.status.busy": "2021-02-15T23:58:19.178973Z",
     "iopub.status.idle": "2021-02-15T23:58:23.416645Z",
     "shell.execute_reply": "2021-02-15T23:58:23.415364Z"
    },
    "papermill": {
     "duration": 4.252196,
     "end_time": "2021-02-15T23:58:23.416800",
     "exception": false,
     "start_time": "2021-02-15T23:58:19.164604",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "103/103 [==============================] - 1s 2ms/step - loss: 0.6930 - accuracy: 0.5240 - mse: 0.2499\n",
      "Epoch 2/20\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5171 - mse: 0.2497\n",
      "Epoch 3/20\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.6919 - accuracy: 0.5225 - mse: 0.2494\n",
      "Epoch 4/20\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.6907 - accuracy: 0.5261 - mse: 0.2488\n",
      "Epoch 5/20\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.6876 - accuracy: 0.5248 - mse: 0.2472\n",
      "Epoch 6/20\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.6781 - accuracy: 0.5918 - mse: 0.2425\n",
      "Epoch 7/20\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.6558 - accuracy: 0.7048 - mse: 0.2314\n",
      "Epoch 8/20\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.6254 - accuracy: 0.7118 - mse: 0.2166\n",
      "Epoch 9/20\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.5936 - accuracy: 0.7139 - mse: 0.2018\n",
      "Epoch 10/20\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.5722 - accuracy: 0.7143 - mse: 0.1925\n",
      "Epoch 11/20\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.5606 - accuracy: 0.7129 - mse: 0.1879\n",
      "Epoch 12/20\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.5539 - accuracy: 0.7132 - mse: 0.1856\n",
      "Epoch 13/20\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.5549 - accuracy: 0.7204 - mse: 0.1864\n",
      "Epoch 14/20\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.5508 - accuracy: 0.7237 - mse: 0.1848\n",
      "Epoch 15/20\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.5502 - accuracy: 0.7233 - mse: 0.1847\n",
      "Epoch 16/20\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.5454 - accuracy: 0.7222 - mse: 0.1828\n",
      "Epoch 17/20\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.5415 - accuracy: 0.7270 - mse: 0.1813\n",
      "Epoch 18/20\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.5408 - accuracy: 0.7306 - mse: 0.1809\n",
      "Epoch 19/20\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.5457 - accuracy: 0.7248 - mse: 0.1831\n",
      "Epoch 20/20\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.5412 - accuracy: 0.7244 - mse: 0.1813\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f4b1b687b50>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now we're going to compile the model\n",
    "#Our loss function is binary crossentropy\n",
    "#Our optimizer is adam\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy', \n",
    "              optimizer = 'adam',\n",
    "              metrics = ['accuracy', 'mse'])\n",
    "\n",
    "#We're going to also fit the model\n",
    "#We're going to do 20 epochs\n",
    "#The batch size will be 224 to get ~100 iterations per epoch\n",
    "model.fit(X_train, y_train, epochs = 20,\n",
    "          batch_size = 224, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-15T23:58:23.503980Z",
     "iopub.status.busy": "2021-02-15T23:58:23.502953Z",
     "iopub.status.idle": "2021-02-15T23:58:24.085963Z",
     "shell.execute_reply": "2021-02-15T23:58:24.085329Z"
    },
    "papermill": {
     "duration": 0.628685,
     "end_time": "2021-02-15T23:58:24.086115",
     "exception": false,
     "start_time": "2021-02-15T23:58:23.457430",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179/179 [==============================] - 0s 957us/step - loss: 0.5532 - accuracy: 0.7098 - mse: 0.1869\n",
      "[0.553242027759552, 0.7098183035850525, 0.18690022826194763]\n",
      "Precision: 0.6560509554140127\n",
      "Recall: 0.804089219330855\n"
     ]
    }
   ],
   "source": [
    "#Next, we'll test the model on the test dataset we set aside\n",
    "\n",
    "#Prediction on the X_test data, round each to an integer (either 0 or 1)\n",
    "y_pred = np.around(model.predict(X_test))\n",
    "\n",
    "#We're going to now look at the accuracy and loss\n",
    "score = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(score)\n",
    "\n",
    "#We'll print precision and recall too\n",
    "print(f\"Precision: {precision_score(y_test, y_pred)}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-15T23:58:24.175962Z",
     "iopub.status.busy": "2021-02-15T23:58:24.175338Z",
     "iopub.status.idle": "2021-02-15T23:58:24.238810Z",
     "shell.execute_reply": "2021-02-15T23:58:24.238293Z"
    },
    "papermill": {
     "duration": 0.112015,
     "end_time": "2021-02-15T23:58:24.238954",
     "exception": false,
     "start_time": "2021-02-15T23:58:24.126939",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 is_sarcastic not_sarcastic\n",
      "0   is_sarcastic         1900          1134\n",
      "1  not_sarcastic          527          2163\n"
     ]
    }
   ],
   "source": [
    "#Now we're going to make a confusion matri\n",
    "#The rows are the known labels, the columns are the predicted labels\n",
    "matrix = cm(y_test, y_pred)\n",
    "df = pd.DataFrame(columns = ['', 'is_sarcastic', 'not_sarcastic'])\n",
    "df.loc[len(df)] = ['is_sarcastic', matrix[0][0], matrix[0][1]]\n",
    "df.loc[len(df)] = ['not_sarcastic', matrix[1][0], matrix[1][1]]\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 20.843599,
   "end_time": "2021-02-15T23:58:26.450641",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-02-15T23:58:05.607042",
   "version": "2.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
