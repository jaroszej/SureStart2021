{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Surestart Action Item Day 5\nThis notebook will train and test a basic neural network, using Keras, to determine whether a headline is sarcastic or not.  "},{"metadata":{"trusted":true},"cell_type":"code","source":"#Necessary packages\nimport pandas as pd\nimport numpy as np\nimport os\nimport json\nfrom sklearn.model_selection import train_test_split as tts\nfrom sklearn.model_selection import cross_val_score as cvs\nimport nltk\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nimport keras\nimport tensorflow as tf\nfrom keras import models\nfrom keras import layers\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom tensorflow.keras.losses import MeanSquaredError as mse\nimport sklearn.metrics\nfrom sklearn.metrics import confusion_matrix as cm\nfrom sklearn.metrics import precision_score, recall_score","execution_count":18,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#Getting pathnames for each file in the input folder\nfor dirname, _, filenames in os.walk('/kaggle/input/news-headlines-dataset-for-sarcasm-detection'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n#Function to parse data\ndef parse_data(file):\n    for l in open(file,'r'):\n        yield json.loads(l)\n\n#Taking in the data in one of the json files (I'm using the slightly larger one)\ndata = list(parse_data(\"/kaggle/input/news-headlines-dataset-for-sarcasm-detection/Sarcasm_Headlines_Dataset_v2.json\"))\ndata[0]","execution_count":19,"outputs":[{"output_type":"stream","text":"/kaggle/input/news-headlines-dataset-for-sarcasm-detection/Sarcasm_Headlines_Dataset_v2.json\n/kaggle/input/news-headlines-dataset-for-sarcasm-detection/Sarcasm_Headlines_Dataset.json\n","name":"stdout"},{"output_type":"execute_result","execution_count":19,"data":{"text/plain":"{'is_sarcastic': 1,\n 'headline': 'thirtysomething scientists unveil doomsday clock of hair loss',\n 'article_link': 'https://www.theonion.com/thirtysomething-scientists-unveil-doomsday-clock-of-hai-1819586205'}"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"****We need to separate the data from this list into X and y****  \nOur X is going to be a vectorized list of words from the headline.  \nOur y is going to be \"is_sarcastic\".  \nTo do this, we're going to use some NLP packages  "},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating our X variable\nvectorizer = TfidfVectorizer(max_features=50, use_idf=False)\nheadlines = [i['headline'] for i in data]\nX = vectorizer.fit_transform(headlines).toarray()\n\n#Creating our y variable\ny = np.ravel([i['is_sarcastic'] for i in data])\n\n#Creating a train and test split\nX_train, X_test, y_train, y_test = tts(X, y, test_size = 0.2, random_state = 1693)","execution_count":20,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Now we're going to build the model with its layers\n\n#Initialize the model\nmodel = Sequential([\n    # first layer\n    Dense(units=24, input_shape=(50,), activation='softmax'),\n    # second layer\n    Dense(12, activation = 'softmax'),\n    # third layer\n    Dense(8, activation = 'softmax'),\n    # output layer\n    Dense(1, activation = 'sigmoid')\n])","execution_count":21,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Now we're going to compile the model\n#Our loss function is binary crossentropy\n#Our optimizer is adam\n\nmodel.compile(loss = 'binary_crossentropy', \n              optimizer = 'adam',\n              metrics = ['accuracy', 'mse'])\n\n#We're going to also fit the model\n#We're going to do 30 epochs\n#The batch size will be 224 to get ~100 iterations per epoch\nmodel.fit(X_train, y_train, epochs = 30,\n          batch_size = 224, verbose = 1)","execution_count":22,"outputs":[{"output_type":"stream","text":"Epoch 1/100\n103/103 [==============================] - 1s 2ms/step - loss: 0.6924 - accuracy: 0.5213 - mse: 0.2496\nEpoch 2/100\n103/103 [==============================] - 0s 2ms/step - loss: 0.6922 - accuracy: 0.5215 - mse: 0.2495: 0s - loss: 0.6922 - accuracy: 0.5212 - mse: 0.24\nEpoch 3/100\n103/103 [==============================] - 0s 2ms/step - loss: 0.6915 - accuracy: 0.5272 - mse: 0.2492\nEpoch 4/100\n103/103 [==============================] - 0s 2ms/step - loss: 0.6911 - accuracy: 0.5212 - mse: 0.2490\nEpoch 5/100\n103/103 [==============================] - 0s 2ms/step - loss: 0.6877 - accuracy: 0.5204 - mse: 0.2473\nEpoch 6/100\n103/103 [==============================] - 0s 2ms/step - loss: 0.6761 - accuracy: 0.5703 - mse: 0.2415\nEpoch 7/100\n103/103 [==============================] - 0s 2ms/step - loss: 0.6503 - accuracy: 0.7009 - mse: 0.2287\nEpoch 8/100\n103/103 [==============================] - 0s 2ms/step - loss: 0.6168 - accuracy: 0.7048 - mse: 0.2125\nEpoch 9/100\n103/103 [==============================] - 0s 2ms/step - loss: 0.5877 - accuracy: 0.7156 - mse: 0.1992\nEpoch 10/100\n103/103 [==============================] - 0s 2ms/step - loss: 0.5681 - accuracy: 0.7171 - mse: 0.1908\nEpoch 11/100\n103/103 [==============================] - 0s 2ms/step - loss: 0.5565 - accuracy: 0.7181 - mse: 0.1861\nEpoch 12/100\n103/103 [==============================] - 0s 2ms/step - loss: 0.5531 - accuracy: 0.7178 - mse: 0.1851\nEpoch 13/100\n103/103 [==============================] - 0s 2ms/step - loss: 0.5484 - accuracy: 0.7269 - mse: 0.1835\nEpoch 14/100\n103/103 [==============================] - 0s 2ms/step - loss: 0.5499 - accuracy: 0.7231 - mse: 0.1844\nEpoch 15/100\n103/103 [==============================] - 0s 2ms/step - loss: 0.5462 - accuracy: 0.7209 - mse: 0.1829\nEpoch 16/100\n103/103 [==============================] - 0s 2ms/step - loss: 0.5490 - accuracy: 0.7214 - mse: 0.1843\nEpoch 17/100\n103/103 [==============================] - 0s 2ms/step - loss: 0.5478 - accuracy: 0.7239 - mse: 0.1838\nEpoch 18/100\n103/103 [==============================] - 0s 2ms/step - loss: 0.5416 - accuracy: 0.7306 - mse: 0.1811\nEpoch 19/100\n103/103 [==============================] - 0s 2ms/step - loss: 0.5431 - accuracy: 0.7276 - mse: 0.1820\nEpoch 20/100\n 30/103 [=======>......................] - ETA: 0s - loss: 0.5432 - accuracy: 0.7269 - mse: 0.1817","name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-aaffa213bae7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#The batch size will be 224 to get ~100 iterations per epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m model.fit(X_train, y_train, epochs = 100,\n\u001b[0;32m---> 13\u001b[0;31m           batch_size = 224, verbose = 1)\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Next, we'll test the model on the test dataset we set aside\n\n#Prediction on the X_test data, round each to an integer (either 0 or 1)\ny_pred = np.around(model.predict(X_test))\n\n#We're going to now look at the accuracy and loss\nscore = model.evaluate(X_test, y_test, verbose=1)\nprint(score)\n\n#We'll print precision and recall too\nprint(f\"Precision: {precision_score(y_test, y_pred)}\")\nprint(f\"Recall: {recall_score(y_test, y_pred)}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Now we're going to make a confusion matrix\n#The rows are the known labels, the columns are the predicted labels\nmatrix = cm(y_test, y_pred)\ndf = pd.DataFrame(columns = ['', 'is_sarcastic', 'not_sarcastic'])\ndf.loc[len(df)] = ['is_sarcastic', matrix[0][0], matrix[0][1]]\ndf.loc[len(df)] = ['not_sarcastic', matrix[1][0], matrix[1][1]]\nprint(df)\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}